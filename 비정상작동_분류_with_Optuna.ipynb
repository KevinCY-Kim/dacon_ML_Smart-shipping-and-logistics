{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KevinCY-Kim/dacon_ML_Smart-shipping-and-logistics/blob/main/%EB%B9%84%EC%A0%95%EC%83%81%EC%9E%91%EB%8F%99_%EB%B6%84%EB%A5%98_with_Optuna.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKwgn2q6Zmz5",
        "outputId": "041c7da8-a3ab-4e32-f252-1582c8906533"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.16.5)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.43)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.9.0 optuna-4.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import optuna"
      ],
      "metadata": {
        "id": "8EWVwdaMZmI7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================\n",
        "# 1. 데이터 로드\n",
        "# =======================\n",
        "train = pd.read_csv(\"train.csv\", sep=\",\")\n",
        "test = pd.read_csv(\"test.csv\", sep=\",\")\n",
        "\n",
        "X = train.drop(columns=[\"ID\", \"target\"])\n",
        "y = train[\"target\"]\n",
        "\n",
        "X_test = test.drop(columns=[\"ID\"])\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
      ],
      "metadata": {
        "id": "GKkhcSyVZqzV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "# =======================\n",
        "# 2. Optuna 목적 함수 정의\n",
        "# =======================\n",
        "def DecisionTreeobjective(trial):\n",
        "    max_depth = trial.suggest_int(\"max_depth\", 2, 20)\n",
        "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 20)\n",
        "    model = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_samples_split, random_state=4)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_valid)\n",
        "    return f1_score(y_valid, y_pred, average=\"macro\")\n",
        "\n",
        "def RandomForestobjective(trial):\n",
        "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 300)\n",
        "    max_depth = trial.suggest_int(\"max_depth\", 2, 20)\n",
        "    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_valid)\n",
        "    return f1_score(y_valid, y_pred, average=\"macro\")\n",
        "\n",
        "def Logisticobjective(trial):\n",
        "    C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
        "    model = LogisticRegression(C=C, max_iter=1000, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_valid)\n",
        "    return f1_score(y_valid, y_pred, average=\"macro\")"
      ],
      "metadata": {
        "id": "w3gSBaZPZufK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================\n",
        "# 3. Optuna 실행\n",
        "# =======================\n",
        "print(\"Tuning Decision Tree...\")\n",
        "study_dt = optuna.create_study(direction=\"maximize\")\n",
        "study_dt.optimize(DecisionTreeobjective, n_trials=50)\n",
        "print(\"Best params (DT):\", study_dt.best_params)\n",
        "\n",
        "print(\"Tuning Random Forest...\")\n",
        "study_rf = optuna.create_study(direction=\"maximize\")\n",
        "study_rf.optimize(RandomForestobjective, n_trials=50)\n",
        "print(\"Best params (RF):\", study_rf.best_params)\n",
        "\n",
        "print(\"Tuning Logistic Regression...\")\n",
        "study_lr = optuna.create_study(direction=\"maximize\")\n",
        "study_lr.optimize(Logisticobjective, n_trials=50)\n",
        "print(\"Best params (LR):\", study_lr.best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TD-Qvp_oZ4_D",
        "outputId": "996f91ea-1b0a-4fe5-e4cf-22532f64e754"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-09-22 00:18:25,404] A new study created in memory with name: no-name-4dde6c1c-697e-44ab-ad7f-84dd46d6c71e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuning Decision Tree...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-09-22 00:18:27,426] Trial 0 finished with value: 0.6252012578868519 and parameters: {'max_depth': 15, 'min_samples_split': 12}. Best is trial 0 with value: 0.6252012578868519.\n",
            "[I 2025-09-22 00:18:29,141] Trial 1 finished with value: 0.5665552036447213 and parameters: {'max_depth': 12, 'min_samples_split': 3}. Best is trial 0 with value: 0.6252012578868519.\n",
            "[I 2025-09-22 00:18:30,380] Trial 2 finished with value: 0.4125724559533743 and parameters: {'max_depth': 8, 'min_samples_split': 14}. Best is trial 0 with value: 0.6252012578868519.\n",
            "[I 2025-09-22 00:18:30,892] Trial 3 finished with value: 0.14750676886317626 and parameters: {'max_depth': 3, 'min_samples_split': 4}. Best is trial 0 with value: 0.6252012578868519.\n",
            "[I 2025-09-22 00:18:33,298] Trial 4 finished with value: 0.6785409408307076 and parameters: {'max_depth': 20, 'min_samples_split': 10}. Best is trial 4 with value: 0.6785409408307076.\n",
            "[I 2025-09-22 00:18:35,758] Trial 5 finished with value: 0.6235099765052856 and parameters: {'max_depth': 15, 'min_samples_split': 18}. Best is trial 4 with value: 0.6785409408307076.\n",
            "[I 2025-09-22 00:18:37,763] Trial 6 finished with value: 0.5822767342228378 and parameters: {'max_depth': 13, 'min_samples_split': 15}. Best is trial 4 with value: 0.6785409408307076.\n",
            "[I 2025-09-22 00:18:39,151] Trial 7 finished with value: 0.46189077311026583 and parameters: {'max_depth': 9, 'min_samples_split': 18}. Best is trial 4 with value: 0.6785409408307076.\n",
            "[I 2025-09-22 00:18:39,982] Trial 8 finished with value: 0.2664724896253119 and parameters: {'max_depth': 5, 'min_samples_split': 19}. Best is trial 4 with value: 0.6785409408307076.\n",
            "[I 2025-09-22 00:18:40,327] Trial 9 finished with value: 0.09998732003089303 and parameters: {'max_depth': 2, 'min_samples_split': 4}. Best is trial 4 with value: 0.6785409408307076.\n",
            "[I 2025-09-22 00:18:42,755] Trial 10 finished with value: 0.6804867231893496 and parameters: {'max_depth': 20, 'min_samples_split': 8}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:18:45,153] Trial 11 finished with value: 0.6804867231893496 and parameters: {'max_depth': 20, 'min_samples_split': 8}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:18:47,952] Trial 12 finished with value: 0.6804867231893496 and parameters: {'max_depth': 20, 'min_samples_split': 8}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:18:50,418] Trial 13 finished with value: 0.6532041192514099 and parameters: {'max_depth': 17, 'min_samples_split': 8}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:18:52,724] Trial 14 finished with value: 0.6575116947701454 and parameters: {'max_depth': 18, 'min_samples_split': 7}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:18:55,225] Trial 15 finished with value: 0.6542711995046055 and parameters: {'max_depth': 17, 'min_samples_split': 6}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:18:58,147] Trial 16 finished with value: 0.6775325344629508 and parameters: {'max_depth': 20, 'min_samples_split': 11}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:19:00,714] Trial 17 finished with value: 0.6246772009416961 and parameters: {'max_depth': 15, 'min_samples_split': 10}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:19:02,399] Trial 18 finished with value: 0.5067291107787795 and parameters: {'max_depth': 10, 'min_samples_split': 2}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:19:04,696] Trial 19 finished with value: 0.6574161730007775 and parameters: {'max_depth': 18, 'min_samples_split': 6}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:19:05,809] Trial 20 finished with value: 0.3655029259510992 and parameters: {'max_depth': 7, 'min_samples_split': 9}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:19:08,256] Trial 21 finished with value: 0.6788690954899359 and parameters: {'max_depth': 20, 'min_samples_split': 13}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:19:10,541] Trial 22 finished with value: 0.6570406052180909 and parameters: {'max_depth': 18, 'min_samples_split': 8}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:19:13,555] Trial 23 finished with value: 0.6796479804214398 and parameters: {'max_depth': 20, 'min_samples_split': 6}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:19:15,694] Trial 24 finished with value: 0.6361760627564125 and parameters: {'max_depth': 16, 'min_samples_split': 9}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:19:17,515] Trial 25 finished with value: 0.5829969654002637 and parameters: {'max_depth': 13, 'min_samples_split': 5}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:19:19,818] Trial 26 finished with value: 0.6622094142874062 and parameters: {'max_depth': 19, 'min_samples_split': 8}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:19:21,995] Trial 27 finished with value: 0.6518636589757261 and parameters: {'max_depth': 17, 'min_samples_split': 12}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:19:24,557] Trial 28 finished with value: 0.6632323030393504 and parameters: {'max_depth': 19, 'min_samples_split': 10}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:19:26,741] Trial 29 finished with value: 0.5822767342228378 and parameters: {'max_depth': 13, 'min_samples_split': 15}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:19:28,838] Trial 30 finished with value: 0.63655476662452 and parameters: {'max_depth': 16, 'min_samples_split': 12}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:19:31,274] Trial 31 finished with value: 0.6796479804214398 and parameters: {'max_depth': 20, 'min_samples_split': 6}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:19:33,594] Trial 32 finished with value: 0.6637236966401378 and parameters: {'max_depth': 19, 'min_samples_split': 6}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:19:35,903] Trial 33 finished with value: 0.6610615727073076 and parameters: {'max_depth': 19, 'min_samples_split': 4}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:19:38,809] Trial 34 finished with value: 0.6570406052180909 and parameters: {'max_depth': 18, 'min_samples_split': 8}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:19:41,295] Trial 35 finished with value: 0.6797727757297233 and parameters: {'max_depth': 20, 'min_samples_split': 7}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:19:43,440] Trial 36 finished with value: 0.6361760627564125 and parameters: {'max_depth': 16, 'min_samples_split': 9}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:19:45,454] Trial 37 finished with value: 0.6251532467075032 and parameters: {'max_depth': 15, 'min_samples_split': 7}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:19:47,381] Trial 38 finished with value: 0.6019384557263032 and parameters: {'max_depth': 14, 'min_samples_split': 11}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:19:49,183] Trial 39 finished with value: 0.5267280808860191 and parameters: {'max_depth': 11, 'min_samples_split': 3}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:19:50,481] Trial 40 finished with value: 0.3213875284178974 and parameters: {'max_depth': 6, 'min_samples_split': 7}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:19:52,937] Trial 41 finished with value: 0.6804267704591388 and parameters: {'max_depth': 20, 'min_samples_split': 5}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:19:55,370] Trial 42 finished with value: 0.6804267704591388 and parameters: {'max_depth': 20, 'min_samples_split': 5}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:19:57,744] Trial 43 finished with value: 0.6645537515058423 and parameters: {'max_depth': 19, 'min_samples_split': 5}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:20:00,024] Trial 44 finished with value: 0.6554719595905311 and parameters: {'max_depth': 18, 'min_samples_split': 2}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:20:02,812] Trial 45 finished with value: 0.6534207322447957 and parameters: {'max_depth': 17, 'min_samples_split': 4}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:20:05,229] Trial 46 finished with value: 0.6645537515058423 and parameters: {'max_depth': 19, 'min_samples_split': 5}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:20:08,149] Trial 47 finished with value: 0.6792296318896537 and parameters: {'max_depth': 20, 'min_samples_split': 3}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:20:10,635] Trial 48 finished with value: 0.657372095397927 and parameters: {'max_depth': 18, 'min_samples_split': 9}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:20:12,847] Trial 49 finished with value: 0.6533031343192213 and parameters: {'max_depth': 17, 'min_samples_split': 10}. Best is trial 10 with value: 0.6804867231893496.\n",
            "[I 2025-09-22 00:20:12,849] A new study created in memory with name: no-name-5e92a53f-e7d9-44f7-a9ef-e5c83a8a6c0f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params (DT): {'max_depth': 20, 'min_samples_split': 8}\n",
            "Tuning Random Forest...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-09-22 00:20:31,720] Trial 0 finished with value: 0.5328657190274627 and parameters: {'n_estimators': 225, 'max_depth': 5}. Best is trial 0 with value: 0.5328657190274627.\n",
            "[I 2025-09-22 00:21:01,267] Trial 1 finished with value: 0.7166296723004318 and parameters: {'n_estimators': 155, 'max_depth': 14}. Best is trial 1 with value: 0.7166296723004318.\n",
            "[I 2025-09-22 00:21:04,184] Trial 2 finished with value: 0.3460360887106805 and parameters: {'n_estimators': 70, 'max_depth': 2}. Best is trial 1 with value: 0.7166296723004318.\n",
            "[I 2025-09-22 00:21:40,096] Trial 3 finished with value: 0.7475746871400928 and parameters: {'n_estimators': 150, 'max_depth': 20}. Best is trial 3 with value: 0.7475746871400928.\n",
            "[I 2025-09-22 00:22:08,889] Trial 4 finished with value: 0.605967238249265 and parameters: {'n_estimators': 296, 'max_depth': 6}. Best is trial 3 with value: 0.7475746871400928.\n",
            "[I 2025-09-22 00:22:20,080] Trial 5 finished with value: 0.6092639296278876 and parameters: {'n_estimators': 100, 'max_depth': 7}. Best is trial 3 with value: 0.7475746871400928.\n",
            "[I 2025-09-22 00:22:54,166] Trial 6 finished with value: 0.7157753813968293 and parameters: {'n_estimators': 194, 'max_depth': 13}. Best is trial 3 with value: 0.7475746871400928.\n",
            "[I 2025-09-22 00:23:09,559] Trial 7 finished with value: 0.6560949739055785 and parameters: {'n_estimators': 121, 'max_depth': 8}. Best is trial 3 with value: 0.7475746871400928.\n",
            "[I 2025-09-22 00:23:49,037] Trial 8 finished with value: 0.6885148119067772 and parameters: {'n_estimators': 253, 'max_depth': 10}. Best is trial 3 with value: 0.7475746871400928.\n",
            "[I 2025-09-22 00:24:02,584] Trial 9 finished with value: 0.6892932886535715 and parameters: {'n_estimators': 80, 'max_depth': 12}. Best is trial 3 with value: 0.7475746871400928.\n",
            "[I 2025-09-22 00:24:38,167] Trial 10 finished with value: 0.7463978311872237 and parameters: {'n_estimators': 151, 'max_depth': 19}. Best is trial 3 with value: 0.7475746871400928.\n",
            "[I 2025-09-22 00:25:15,358] Trial 11 finished with value: 0.7472339719786575 and parameters: {'n_estimators': 156, 'max_depth': 20}. Best is trial 3 with value: 0.7475746871400928.\n",
            "[I 2025-09-22 00:25:59,143] Trial 12 finished with value: 0.7481984191470955 and parameters: {'n_estimators': 184, 'max_depth': 20}. Best is trial 12 with value: 0.7481984191470955.\n",
            "[I 2025-09-22 00:26:43,218] Trial 13 finished with value: 0.7369095712684067 and parameters: {'n_estimators': 201, 'max_depth': 17}. Best is trial 12 with value: 0.7481984191470955.\n",
            "[I 2025-09-22 00:27:10,754] Trial 14 finished with value: 0.7385559580639788 and parameters: {'n_estimators': 127, 'max_depth': 17}. Best is trial 12 with value: 0.7481984191470955.\n",
            "[I 2025-09-22 00:28:00,033] Trial 15 finished with value: 0.7353139474392031 and parameters: {'n_estimators': 235, 'max_depth': 16}. Best is trial 12 with value: 0.7481984191470955.\n",
            "[I 2025-09-22 00:28:44,625] Trial 16 finished with value: 0.7499512329021206 and parameters: {'n_estimators': 182, 'max_depth': 20}. Best is trial 16 with value: 0.7499512329021206.\n",
            "[I 2025-09-22 00:29:24,683] Trial 17 finished with value: 0.7345769388485276 and parameters: {'n_estimators': 189, 'max_depth': 16}. Best is trial 16 with value: 0.7499512329021206.\n",
            "[I 2025-09-22 00:30:26,495] Trial 18 finished with value: 0.7426731642496636 and parameters: {'n_estimators': 267, 'max_depth': 18}. Best is trial 16 with value: 0.7499512329021206.\n",
            "[I 2025-09-22 00:31:09,853] Trial 19 finished with value: 0.7216358517376216 and parameters: {'n_estimators': 215, 'max_depth': 15}. Best is trial 16 with value: 0.7499512329021206.\n",
            "[I 2025-09-22 00:31:37,810] Trial 20 finished with value: 0.6921985220055802 and parameters: {'n_estimators': 184, 'max_depth': 10}. Best is trial 16 with value: 0.7499512329021206.\n",
            "[I 2025-09-22 00:32:17,142] Trial 21 finished with value: 0.7475848485566785 and parameters: {'n_estimators': 163, 'max_depth': 20}. Best is trial 16 with value: 0.7499512329021206.\n",
            "[I 2025-09-22 00:32:57,745] Trial 22 finished with value: 0.7479537819607045 and parameters: {'n_estimators': 169, 'max_depth': 20}. Best is trial 16 with value: 0.7499512329021206.\n",
            "[I 2025-09-22 00:33:28,209] Trial 23 finished with value: 0.7392302067593016 and parameters: {'n_estimators': 132, 'max_depth': 18}. Best is trial 16 with value: 0.7499512329021206.\n",
            "[I 2025-09-22 00:34:06,575] Trial 24 finished with value: 0.7414114565946492 and parameters: {'n_estimators': 171, 'max_depth': 18}. Best is trial 16 with value: 0.7499512329021206.\n",
            "[I 2025-09-22 00:34:55,769] Trial 25 finished with value: 0.7486175379418226 and parameters: {'n_estimators': 203, 'max_depth': 20}. Best is trial 16 with value: 0.7499512329021206.\n",
            "[I 2025-09-22 00:35:42,750] Trial 26 finished with value: 0.7424762081552353 and parameters: {'n_estimators': 210, 'max_depth': 18}. Best is trial 16 with value: 0.7499512329021206.\n",
            "[I 2025-09-22 00:36:30,896] Trial 27 finished with value: 0.7211364891670895 and parameters: {'n_estimators': 243, 'max_depth': 15}. Best is trial 16 with value: 0.7499512329021206.\n",
            "[I 2025-09-22 00:37:36,867] Trial 28 finished with value: 0.7451114864325534 and parameters: {'n_estimators': 274, 'max_depth': 19}. Best is trial 16 with value: 0.7499512329021206.\n",
            "[I 2025-09-22 00:37:44,838] Trial 29 finished with value: 0.3941283163994856 and parameters: {'n_estimators': 222, 'max_depth': 2}. Best is trial 16 with value: 0.7499512329021206.\n",
            "[I 2025-09-22 00:37:57,355] Trial 30 finished with value: 0.4958835934416696 and parameters: {'n_estimators': 183, 'max_depth': 4}. Best is trial 16 with value: 0.7499512329021206.\n",
            "[I 2025-09-22 00:38:46,991] Trial 31 finished with value: 0.7479450209756807 and parameters: {'n_estimators': 205, 'max_depth': 20}. Best is trial 16 with value: 0.7499512329021206.\n",
            "[I 2025-09-22 00:39:27,301] Trial 32 finished with value: 0.7456995628878582 and parameters: {'n_estimators': 172, 'max_depth': 19}. Best is trial 16 with value: 0.7499512329021206.\n",
            "[I 2025-09-22 00:39:57,068] Trial 33 finished with value: 0.7372444540272338 and parameters: {'n_estimators': 136, 'max_depth': 17}. Best is trial 16 with value: 0.7499512329021206.\n",
            "[I 2025-09-22 00:40:50,383] Trial 34 finished with value: 0.7477094219035385 and parameters: {'n_estimators': 222, 'max_depth': 20}. Best is trial 16 with value: 0.7499512329021206.\n",
            "[I 2025-09-22 00:41:16,067] Trial 35 finished with value: 0.7448615808158274 and parameters: {'n_estimators': 111, 'max_depth': 19}. Best is trial 16 with value: 0.7499512329021206.\n",
            "[I 2025-09-22 00:41:43,772] Trial 36 finished with value: 0.7175875141129585 and parameters: {'n_estimators': 144, 'max_depth': 14}. Best is trial 16 with value: 0.7499512329021206.\n",
            "[I 2025-09-22 00:42:19,113] Trial 37 finished with value: 0.732310742081775 and parameters: {'n_estimators': 168, 'max_depth': 16}. Best is trial 16 with value: 0.7499512329021206.\n",
            "[I 2025-09-22 00:43:06,008] Trial 38 finished with value: 0.7490624702456017 and parameters: {'n_estimators': 198, 'max_depth': 20}. Best is trial 16 with value: 0.7499512329021206.\n",
            "[I 2025-09-22 00:43:51,544] Trial 39 finished with value: 0.7447137330158017 and parameters: {'n_estimators': 196, 'max_depth': 19}. Best is trial 16 with value: 0.7499512329021206.\n",
            "[I 2025-09-22 00:44:36,075] Trial 40 finished with value: 0.7165156738862134 and parameters: {'n_estimators': 245, 'max_depth': 13}. Best is trial 16 with value: 0.7499512329021206.\n",
            "[I 2025-09-22 00:45:19,350] Trial 41 finished with value: 0.7499512329021206 and parameters: {'n_estimators': 182, 'max_depth': 20}. Best is trial 16 with value: 0.7499512329021206.\n",
            "[I 2025-09-22 00:46:00,276] Trial 42 finished with value: 0.7410029378238043 and parameters: {'n_estimators': 183, 'max_depth': 18}. Best is trial 16 with value: 0.7499512329021206.\n",
            "[I 2025-09-22 00:46:48,305] Trial 43 finished with value: 0.7481081253043576 and parameters: {'n_estimators': 201, 'max_depth': 20}. Best is trial 16 with value: 0.7499512329021206.\n",
            "[I 2025-09-22 00:47:41,788] Trial 44 finished with value: 0.7456854810841745 and parameters: {'n_estimators': 228, 'max_depth': 19}. Best is trial 16 with value: 0.7499512329021206.\n",
            "[I 2025-09-22 00:47:52,283] Trial 45 finished with value: 0.7299277318864034 and parameters: {'n_estimators': 50, 'max_depth': 17}. Best is trial 16 with value: 0.7499512329021206.\n",
            "[I 2025-09-22 00:48:43,565] Trial 46 finished with value: 0.7475923474748173 and parameters: {'n_estimators': 212, 'max_depth': 20}. Best is trial 16 with value: 0.7499512329021206.\n",
            "[I 2025-09-22 00:49:01,748] Trial 47 finished with value: 0.6511540753171667 and parameters: {'n_estimators': 150, 'max_depth': 8}. Best is trial 16 with value: 0.7499512329021206.\n",
            "[I 2025-09-22 00:49:43,611] Trial 48 finished with value: 0.7444400308500215 and parameters: {'n_estimators': 180, 'max_depth': 19}. Best is trial 16 with value: 0.7499512329021206.\n",
            "[I 2025-09-22 00:50:26,147] Trial 49 finished with value: 0.7361257931649539 and parameters: {'n_estimators': 197, 'max_depth': 17}. Best is trial 16 with value: 0.7499512329021206.\n",
            "[I 2025-09-22 00:50:26,148] A new study created in memory with name: no-name-2abee634-d91f-4e34-b02e-3a094393df2f\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params (RF): {'n_estimators': 182, 'max_depth': 20}\n",
            "Tuning Logistic Regression...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 00:51:15,747] Trial 0 finished with value: 0.49787335054875503 and parameters: {'C': 2.2023737503967267}. Best is trial 0 with value: 0.49787335054875503.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 00:52:01,449] Trial 1 finished with value: 0.3527522139212602 and parameters: {'C': 0.0016398611871583874}. Best is trial 0 with value: 0.49787335054875503.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 00:52:50,291] Trial 2 finished with value: 0.5049904652705692 and parameters: {'C': 1.4550565660778063}. Best is trial 2 with value: 0.5049904652705692.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 00:53:37,931] Trial 3 finished with value: 0.5058386285116954 and parameters: {'C': 8.584834238832022}. Best is trial 3 with value: 0.5058386285116954.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 00:54:24,481] Trial 4 finished with value: 0.41537856054805966 and parameters: {'C': 0.023906611069736138}. Best is trial 3 with value: 0.5058386285116954.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 00:55:13,420] Trial 5 finished with value: 0.34421572727642236 and parameters: {'C': 0.0012189428366828896}. Best is trial 3 with value: 0.5058386285116954.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 00:55:58,732] Trial 6 finished with value: 0.4090654436273224 and parameters: {'C': 0.014291228282808786}. Best is trial 3 with value: 0.5058386285116954.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 00:56:45,255] Trial 7 finished with value: 0.4792737243134222 and parameters: {'C': 0.18426494083698655}. Best is trial 3 with value: 0.5058386285116954.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 00:57:32,827] Trial 8 finished with value: 0.3916145603766397 and parameters: {'C': 0.009328649990346645}. Best is trial 3 with value: 0.5058386285116954.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 00:58:20,972] Trial 9 finished with value: 0.4981346593580311 and parameters: {'C': 0.5532553052038218}. Best is trial 3 with value: 0.5058386285116954.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 00:59:08,621] Trial 10 finished with value: 0.5019796439758982 and parameters: {'C': 9.794802234753961}. Best is trial 3 with value: 0.5058386285116954.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 00:59:59,194] Trial 11 finished with value: 0.495907178018363 and parameters: {'C': 9.31712363663979}. Best is trial 3 with value: 0.5058386285116954.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:00:46,048] Trial 12 finished with value: 0.4998963872296413 and parameters: {'C': 1.2618115000184698}. Best is trial 3 with value: 0.5058386285116954.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:01:32,210] Trial 13 finished with value: 0.5062868185068953 and parameters: {'C': 3.7229039948331324}. Best is trial 13 with value: 0.5062868185068953.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:02:20,245] Trial 14 finished with value: 0.5046175928102925 and parameters: {'C': 3.9054525608239183}. Best is trial 13 with value: 0.5062868185068953.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:03:06,506] Trial 15 finished with value: 0.4934519222889803 and parameters: {'C': 0.2989476785116179}. Best is trial 13 with value: 0.5062868185068953.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:03:54,370] Trial 16 finished with value: 0.45587395226374855 and parameters: {'C': 0.05484245441133289}. Best is trial 13 with value: 0.5062868185068953.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:04:42,420] Trial 17 finished with value: 0.49214487378445976 and parameters: {'C': 0.6224006210806834}. Best is trial 13 with value: 0.5062868185068953.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:05:29,824] Trial 18 finished with value: 0.503631759003349 and parameters: {'C': 3.787944049508567}. Best is trial 13 with value: 0.5062868185068953.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:06:17,608] Trial 19 finished with value: 0.4665086407788038 and parameters: {'C': 0.08133891243750631}. Best is trial 13 with value: 0.5062868185068953.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:07:04,838] Trial 20 finished with value: 0.5050346787809842 and parameters: {'C': 4.578653947104873}. Best is trial 13 with value: 0.5062868185068953.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:07:52,252] Trial 21 finished with value: 0.5092598927402611 and parameters: {'C': 4.849495434793366}. Best is trial 21 with value: 0.5092598927402611.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:08:37,948] Trial 22 finished with value: 0.4965747956368254 and parameters: {'C': 0.7836796485840614}. Best is trial 21 with value: 0.5092598927402611.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:09:25,489] Trial 23 finished with value: 0.5058881753445268 and parameters: {'C': 2.5194761336846434}. Best is trial 21 with value: 0.5092598927402611.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:10:13,453] Trial 24 finished with value: 0.5003995159252339 and parameters: {'C': 2.1554442057301264}. Best is trial 21 with value: 0.5092598927402611.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:11:01,084] Trial 25 finished with value: 0.4915472333298863 and parameters: {'C': 0.3782793118837247}. Best is trial 21 with value: 0.5092598927402611.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:11:48,689] Trial 26 finished with value: 0.5016976852280188 and parameters: {'C': 4.29955827147204}. Best is trial 21 with value: 0.5092598927402611.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:12:33,720] Trial 27 finished with value: 0.4968926042121235 and parameters: {'C': 1.1211705987545686}. Best is trial 21 with value: 0.5092598927402611.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:13:20,946] Trial 28 finished with value: 0.48679388050725203 and parameters: {'C': 0.17329978502875334}. Best is trial 21 with value: 0.5092598927402611.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:14:09,157] Trial 29 finished with value: 0.4935741242426812 and parameters: {'C': 2.3470905584938904}. Best is trial 21 with value: 0.5092598927402611.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:14:54,798] Trial 30 finished with value: 0.4956910262675184 and parameters: {'C': 2.0438827272703257}. Best is trial 21 with value: 0.5092598927402611.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:15:43,693] Trial 31 finished with value: 0.5055390368935567 and parameters: {'C': 8.737060904440513}. Best is trial 21 with value: 0.5092598927402611.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:16:33,110] Trial 32 finished with value: 0.5001376474129239 and parameters: {'C': 6.149785354895895}. Best is trial 21 with value: 0.5092598927402611.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:17:18,983] Trial 33 finished with value: 0.5074357666515333 and parameters: {'C': 2.744398064116084}. Best is trial 21 with value: 0.5092598927402611.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:18:06,571] Trial 34 finished with value: 0.3616972602949116 and parameters: {'C': 0.0035958505760100594}. Best is trial 21 with value: 0.5092598927402611.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:18:53,701] Trial 35 finished with value: 0.49568616689895884 and parameters: {'C': 2.6436773409977734}. Best is trial 21 with value: 0.5092598927402611.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:19:40,416] Trial 36 finished with value: 0.5036533354589009 and parameters: {'C': 1.3890548703087924}. Best is trial 21 with value: 0.5092598927402611.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:20:29,187] Trial 37 finished with value: 0.5014773209088281 and parameters: {'C': 0.9105633935695823}. Best is trial 21 with value: 0.5092598927402611.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:21:16,860] Trial 38 finished with value: 0.5098894691594357 and parameters: {'C': 5.969780879014203}. Best is trial 38 with value: 0.5098894691594357.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:22:02,692] Trial 39 finished with value: 0.4984110951223335 and parameters: {'C': 5.489257485627172}. Best is trial 38 with value: 0.5098894691594357.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:22:50,304] Trial 40 finished with value: 0.5094552805238143 and parameters: {'C': 5.890430342106535}. Best is trial 38 with value: 0.5098894691594357.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:23:37,760] Trial 41 finished with value: 0.5085226548624338 and parameters: {'C': 6.24108018083985}. Best is trial 38 with value: 0.5098894691594357.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:24:24,034] Trial 42 finished with value: 0.5081172725381414 and parameters: {'C': 6.573999708493605}. Best is trial 38 with value: 0.5098894691594357.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:25:10,724] Trial 43 finished with value: 0.5040681940207027 and parameters: {'C': 6.577917205931665}. Best is trial 38 with value: 0.5098894691594357.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:25:56,037] Trial 44 finished with value: 0.5047988823015244 and parameters: {'C': 6.543567356510555}. Best is trial 38 with value: 0.5098894691594357.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:26:43,985] Trial 45 finished with value: 0.5075023663185034 and parameters: {'C': 9.895142612441878}. Best is trial 38 with value: 0.5098894691594357.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:27:31,168] Trial 46 finished with value: 0.5057005183202145 and parameters: {'C': 1.7623836091148217}. Best is trial 38 with value: 0.5098894691594357.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:28:17,365] Trial 47 finished with value: 0.5071786965631754 and parameters: {'C': 6.399317855103644}. Best is trial 38 with value: 0.5098894691594357.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:29:05,177] Trial 48 finished with value: 0.4994079564349538 and parameters: {'C': 3.104511285486247}. Best is trial 38 with value: 0.5098894691594357.\n",
            "/tmp/ipython-input-247389688.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform(\"C\", 1e-3, 10)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-09-22 01:29:53,949] Trial 49 finished with value: 0.44413522648063924 and parameters: {'C': 0.031479680386151496}. Best is trial 38 with value: 0.5098894691594357.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params (LR): {'C': 5.969780879014203}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================\n",
        "# 4. 최적 모델 생성\n",
        "# =======================\n",
        "dt_best = DecisionTreeClassifier(**study_dt.best_params, random_state=42)\n",
        "rf_best = RandomForestClassifier(**study_rf.best_params, random_state=42)\n",
        "lr_best = LogisticRegression(**study_lr.best_params, max_iter=1000, random_state=42)"
      ],
      "metadata": {
        "id": "ph6Rv6AgZ7sU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# =======================\n",
        "# 5. 스태킹\n",
        "# =======================\n",
        "\n",
        "# GridSearchCV 결과에서 최적 모델 뽑기\n",
        "dt_best = dt_grid.best_estimator_\n",
        "rf_best = rf_grid.best_estimator_\n",
        "lr_best = lr_grid.best_estimator_\n",
        "\n",
        "estimators = [\n",
        "    ('dt', dt_best),\n",
        "    ('rf', rf_best)\n",
        "]\n",
        "\n",
        "stack_model = StackingClassifier(\n",
        "    estimators=estimators,\n",
        "    final_estimator=lr_best,\n",
        "    passthrough=True  # 전방모델 예측결과도 함께 사용\n",
        ")\n",
        "\n",
        "# 학습\n",
        "stack_model.fit(X_train, y_train)\n",
        "\n",
        "# 검증 예측\n",
        "y_pred = stack_model.predict(X_valid)\n",
        "\n",
        "# 성능 출력\n",
        "print(\"Accuracy:\", accuracy_score(y_valid, y_pred))\n",
        "print(\"F1 Score:\", f1_score(y_valid, y_pred))"
      ],
      "metadata": {
        "id": "Hbua5aqrFzR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 위에꺼 사용\n",
        "# =======================\n",
        "# 5. 스태킹\n",
        "# =======================\n",
        "estimators = [\n",
        "    ('dt', dt_best),\n",
        "    ('rf', rf_best)\n",
        "]\n",
        "\n",
        "stack_model = StackingClassifier(\n",
        "    estimators=estimators,\n",
        "    final_estimator=lr_best,\n",
        "    passthrough=True  # 전방모델 예측결과도 함께 사용\n",
        ")\n",
        "\n",
        "stack_model.fit(X_train, y_train)\n",
        "y_pred = stack_model.predict(X_valid)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_valid, y_pred))\n",
        "print(\"F1 Score:\", f1_score(y_valid, y_pred))\n"
      ],
      "metadata": {
        "id": "Deg96wNsZ9tq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "904b38bf-1f99-494f-82c1-76299d191298"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7259737266651302\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3525294258.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"F1 Score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.66666667\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m        \u001b[0;34m,\u001b[0m \u001b[0;36m0.66666667\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m     \"\"\"\n\u001b[0;32m-> 1324\u001b[0;31m     return fbeta_score(\n\u001b[0m\u001b[1;32m   1325\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mglobal_skip_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"skip_parameter_validation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mfunc_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1515\u001b[0m     \"\"\"\n\u001b[1;32m   1516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1517\u001b[0;31m     _, _, f, _ = precision_recall_fscore_support(\n\u001b[0m\u001b[1;32m   1518\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mglobal_skip_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"skip_parameter_validation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mfunc_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1828\u001b[0m     \"\"\"\n\u001b[1;32m   1829\u001b[0m     \u001b[0m_check_zero_division\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1830\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1832\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1611\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m                 \u001b[0maverage_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"samples\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1613\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1614\u001b[0m                 \u001b[0;34m\"Target is %s but average='binary'. Please \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1615\u001b[0m                 \u001b[0;34m\"choose another average setting, one of %r.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_valid, y_pred))\n",
        "print(\"F1 Score (macro):\", f1_score(y_valid, y_pred, average=\"macro\"))\n",
        "print(\"F1 Score (weighted):\", f1_score(y_valid, y_pred, average=\"weighted\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ck9QCrLLEeNj",
        "outputId": "8a7a5583-4fdc-4b71-a19c-6e7afdd55281"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7259737266651302\n",
            "F1 Score (macro): 0.7354822179055702\n",
            "F1 Score (weighted): 0.7355854639380877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================\n",
        "# 6. 최종 예측\n",
        "# =======================\n",
        "X_test = test.drop(columns=[\"ID\"])\n",
        "test_pred = stack_model.predict(X_test)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"ID\": test[\"ID\"],\n",
        "    \"target\": test_pred\n",
        "})\n",
        "\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"submission.csv 파일 생성 완료!\")"
      ],
      "metadata": {
        "id": "9KQ2BxCcaAdT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "461ad4eb-9749-4c79-eef7-66414224e3e9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission.csv 파일 생성 완료!\n"
          ]
        }
      ]
    }
  ]
}